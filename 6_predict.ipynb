{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install implicit==0.7.1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\nimport numpy as np\nimport pandas as pd\nfrom scipy.sparse import csr_matrix\nfrom gensim.models.word2vec import Word2Vec\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n\nfolder = '/kaggle/input/prediction-datasets/'\n\npairs_cat = pd.read_csv(folder + 'pairs_categories.csv')\npairs = pd.read_csv(folder + 'pairs.csv')\nitem2category = pd.read_csv(folder + 'item_id_categ_map.csv', sep=';')\nreceipt_2idx = pd.read_pickle(folder + 'receipt_2idx.pkl')\nitem_2idx = pd.read_pickle(folder + 'item_2idx.pkl')\nidx_2item = pd.read_pickle(folder + 'idx_2item.pkl')\nquantity_total_hist_device = pd.read_csv(folder + 'quantity_total_hist_device.csv')\nquantity_total_hist = pd.read_csv(folder + 'quantity_total_hist.csv')\n\ncat_model_cosmetic = Word2Vec.load(folder + 'word2vec.model')\nclassifier = joblib.load(folder + 'classifier_model.joblib')['model']\nals_model = joblib.load(folder + 'candidate_model.joblib')['model']\nitem_norms, item_vecs_csr, item_vecs = get_als_embeddings(als_model)\n\nnum_recs = 10\nnon_features = [\"device_id\", \"item_id\", \"candidate\", \"y\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-09T23:32:53.848019Z","iopub.execute_input":"2023-09-09T23:32:53.848540Z","iopub.status.idle":"2023-09-09T23:32:53.853838Z","shell.execute_reply.started":"2023-09-09T23:32:53.848501Z","shell.execute_reply":"2023-09-09T23:32:53.852582Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"code","source":"def recommend_to_receipt(receipt_cat, sparse_user_item,\n                         receipt_vecs, item_vecs, idx_2item, num_items=5):\n\n    receipt_interactions = sparse_user_item[receipt_cat, :].toarray()\n\n    receipt_interactions = receipt_interactions.reshape(-1) + 1\n    receipt_interactions[receipt_interactions > 1] = 0\n\n    rec_vector = receipt_vecs[receipt_cat, :].dot(item_vecs.T).toarray()\n\n    recommend_vector = (receipt_interactions * rec_vector)[0]\n\n    item_idx = np.argsort(recommend_vector)[::-1][:num_items]\n\n    result = []\n\n    for idx in item_idx:\n        result.append((idx_2item[idx], recommend_vector[idx]))\n\n    return result\n\n\ndef recommend_to_items(items_cat, item_norms, item_vecs, idx_2item, num_items=5):\n\n    scores = item_vecs.dot(item_vecs[items_cat].T).T  / item_norms.reshape(1, -1)\n    top_idx = np.argpartition(scores, -num_items, axis=1)[:, -(num_items+1):]\n    scores = np.array([scores[idx, row] for idx, row in enumerate(top_idx)])\n    scores = scores / item_norms[items_cat].reshape(-1, 1)\n    result = []\n    for i in sorted(zip(top_idx.reshape(-1), scores.reshape(-1)), key=lambda x: -x[1]):\n      if i[0] not in items_cat and idx_2item[i[0]] not in [j[0] for j in result]:\n        result.append((idx_2item[i[0]], i[1]))\n\n    return result[:num_items]\n\n\ndef get_als_embeddings(als_model):\n    # извлечение эмбедов из ALS\n    receipt_vecs = als_model.user_factors\n    item_vecs = als_model.item_factors\n\n    receipt_vecs_csr = csr_matrix(receipt_vecs)\n    item_vecs_csr = csr_matrix(item_vecs)\n\n    item_norms = np.sqrt((item_vecs * item_vecs).sum(axis=1))\n    return item_norms, item_vecs_csr, item_vecs\n\n\ndef predict(item_ids, device_id):\n    predict = pd.DataFrame([device_id], columns = [\"device_id\"])\n    predict[\"item_id\"] = [item_ids]\n\n\n    predict[\"receipt_cat\"] = predict[\"item_id\"].map(receipt_2idx.get)\n    predict[\"item_cat\"] = predict[\"item_id\"].apply(lambda x: [item_2idx.get(i) for i in x if i in item_2idx])\n    predict[\"preds\"] = predict.apply(\n        lambda x:\n        recommend_to_receipt(int(x[\"receipt_cat\"]), sparse_receipt_item, receipt_vecs_csr, item_vecs_csr, idx_2item, num_recs)\n        if not pd.isnull(x[\"receipt_cat\"])\n        else recommend_to_items(x[\"item_cat\"], item_norms, item_vecs, idx_2item, num_recs), axis=1)\n\n    predict = predict \\\n      .drop([\"receipt_cat\", \"item_cat\"], axis=1) \\\n      .explode(\"preds\") \\\n      .explode(\"item_id\") \\\n      .reset_index(drop=True)\n\n    predict = pd.concat([predict, pd.DataFrame(predict[\"preds\"].tolist(), columns=[\"candidate\", \"als_score\"])], axis=1) \\\n      .drop([\"preds\"], axis=1)\n\n    predict = predict.merge(pairs, on=[\"item_id\", \"candidate\"], how=\"left\") \\\n      .merge(quantity_total_hist_device.rename(columns={\"item_id\": \"candidate\"}), on=[\"device_id\", \"candidate\"], how=\"left\") \\\n      .merge(quantity_total_hist.rename(columns={\"item_id\": \"candidate\"}), on=[\"candidate\"], how=\"left\")\n\n    predict = predict \\\n      .merge(item2category, on=[\"item_id\"], how=\"left\") \\\n      .merge(item2category.rename(columns={\"item_id\": \"candidate\", \"category_noun\": \"category_noun_candidate\"}), on=[\"candidate\"], how=\"left\") \\\n      .merge(pairs_cat, on=[\"category_noun\", \"category_noun_candidate\"], how=\"left\")\n\n    predict.loc[predict[\"candidate\"].notna(), \"w2v_sim\"] = predict[predict[\"candidate\"].notna()].apply(lambda x: \n                                              cosine_similarity(cat_model_cosmetic.wv.get_vector(x[\"category_noun\"]).reshape(1, -1),\n                                                                cat_model_cosmetic.wv.get_vector(x[\"category_noun_candidate\"]).reshape(1, -1))[0, 0],\n                                              axis=1\n                                              )\n    predict.drop([\"category_noun\", \"category_noun_candidate\"], axis=1, inplace=True)\n    predict[\"proba\"] = (classifier.predict_proba(predict.drop([i for i in non_features if i != \"y\"], axis=1).fillna(0))[:, 1] * 100).round(2)\n\n    return predict.sort_values(by='proba', ascending=False).head(1)['candidate'].values[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-09T23:33:09.367169Z","iopub.execute_input":"2023-09-09T23:33:09.367644Z","iopub.status.idle":"2023-09-09T23:33:09.385848Z","shell.execute_reply.started":"2023-09-09T23:33:09.367606Z","shell.execute_reply":"2023-09-09T23:33:09.384301Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"code","source":"item_ids = (200361, 200347, 200511, 200543)\ndevice_id = 352398083991747","metadata":{"execution":{"iopub.status.busy":"2023-09-09T23:39:14.588652Z","iopub.execute_input":"2023-09-09T23:39:14.589051Z","iopub.status.idle":"2023-09-09T23:39:14.595284Z","shell.execute_reply.started":"2023-09-09T23:39:14.589019Z","shell.execute_reply":"2023-09-09T23:39:14.593610Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"%%time\npredict(item_ids, device_id)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T23:39:51.336085Z","iopub.execute_input":"2023-09-09T23:39:51.336535Z","iopub.status.idle":"2023-09-09T23:39:51.436880Z","shell.execute_reply.started":"2023-09-09T23:39:51.336503Z","shell.execute_reply":"2023-09-09T23:39:51.436105Z"},"trusted":true},"execution_count":195,"outputs":[{"name":"stdout","text":"CPU times: user 91.6 ms, sys: 3.09 ms, total: 94.7 ms\nWall time: 92.7 ms\n","output_type":"stream"},{"execution_count":195,"output_type":"execute_result","data":{"text/plain":"200551"},"metadata":{}}]}]}